# web-scraping
HHA 507, Assignment 7, AHI, SBU


1. Create a new github repo called 'web-scraping' 

2. Using BS4, find at least 2 websites that you want to scrap data from - provide that code within a .py file  

3. In the code, for each website - create at least one dataframe that has structured data 

4. Save each of the dataframes as separate .csv files into a "/data" folder within your repo - be sure to include the .csv files within your repo (make sure they are small, < 25mb) 

4. Include a markdown file in the repo which includes instructions (e.g., what are the required python packages to run this, your approach for scrapping the data - the div/classes/css tags you found to extract the information)
